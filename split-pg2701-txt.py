#!/usr/bin/python3
# 
# The sole purpose of this script is to split the Project Gutenberg
# plain text file of Moby-Dick into chapters and sentences. Output
# is plain text also in a simple format for downstream processing.
# 
# The script is tuned to work with a specially (hopefully slightly)
# modified version of the plain text edition #2701 from Project
# Gutenberg, which is archived with the script here:
# 
#   https://github.com/dezmoleski/moby-dick
# 
# This script is Copyright (C) 2025 Dez Moleski dez@moleski.com
# MIT License: All uses allowed with attribution.
# 
# The output of this script is in the public domain.
# 
import sys
import re
from dataclasses import dataclass
from dataclasses import field
from wordgames import Word,WordList

MOBY_STR = ''

@dataclass()
class Chapter:
    number: int
    title: str
    title_offset: int
    text_offset: int
    end_offset: int = 0
    
    def __len__(self) -> int:
        if self.end_offset > self.text_offset:
            return self.end_offset -  self.text_offset
        return 0

    def __repr__(self) -> str:
        return f'Ch. {self.number} "{self.title}" {self.text_offset} - {self.end_offset}'
    
    def text(self) -> str:
        if len(self) > 0:
            return MOBY_STR[self.text_offset:self.end_offset]
        return ''

@dataclass()
class Paragraph:
    number: int # absolute index, 1-based
    chapter_number: int # chapter containing this paragraph
    chapter_index: int # 1-based index of this paragraph in the chapter
    start_offset: int # character offset into MOBY_STR of paragraph start
    end_offset: int # character offset into MOBY_STR of paragraph end
    is_pre: bool # True if paragraph is pre-formatted i.e. indented by two spaces
    is_footnote: bool # True if first non-whitespace character of para is '*'
    word_count: int = 0
    
    def __len__(self) -> int:
        if self.end_offset > self.start_offset:
            return self.end_offset -  self.start_offset
        return 0

    def __repr__(self) -> str:
        pre = 'PRE' if self.is_pre else ''
        foot = 'FOOT' if self.is_footnote else ''
        return f'para#{self.number} para:{self.chapter_number}:{self.chapter_index} {self.start_offset} - {self.end_offset} {pre} {foot}'
    
    def text(self) -> str:
        if len(self) > 0:
            return MOBY_STR[self.start_offset:self.end_offset]
        return ''

def split_moby_dick(filepath: str):
    global MOBY_STR
    
    with open(filepath, 'rt') as f:
        MOBY_STR = f.read()
    print("# Moby-Dick split into chapters, paragraphs, and sentences from source file:", filepath, " len:", len(MOBY_STR))
    print("#")
    print("# The contents of this output file are in the public domain. This output file was generated by a")
    print("# script 'split-pg2701-txt.py' which is archived at https://github.com/dezmoleski/moby-dick")
    print("#")
    print("# Chapter header lines are of the form: 'Ch. <number> \"<title>\" <start offset> - <end offset>'")
    print("#")
    print("# Paragraph header lines are of the form: 'para#<number> para:<chapter>:<index> <start offset> - <end offset> [PRE] [FOOT]'")
    print("# where: <number> is the absolute paragraph index (1-based) within the entire book;")
    print("#        <chapter> is the chapter number containing the paragraph;")
    print("#        <index> is the paragraph index (1-based) within the chapter;")
    print("#        PRE indicates the paragraph is a pre-formatted paragraph;")
    print("#        FOOT indicates the paragraph is a footnote;")
    print("#")
    print("# All offsets are zero-based character offsets relative to the start of the source file.")
    print("#")
    
    ##########################
    # PHASE I - Find chapters
    ##########################
    contents = dict() # {<chapter number>:"Chapter Title", ...}
    chapters = list() # of Chapter instances
    
    # We have a couple special cases right off the bat: the ETYMOLOGY and EXTRACTS.
    # My interest here is to catalog the sentences that are original to Melville,
    # so the sections other than the intro paragraphs are not part of the main
    # index. The plan though is to keep all the text of the book in the output, so
    # there is going to be some **TBD** markup for pre-formatted sections that are
    # not included in the chapter/paragraph/sentence index.
    etymology_re = r'^ETYMOLOGY .+\.$'
    re_etymology = re.compile(etymology_re, re.MULTILINE)
    etym = None
    ETYM_INDEX = -1
    for etym_match in re_etymology.finditer(MOBY_STR):
        title = etym_match.group()[0:-1] # Take the whole matching string minus the period.
        if contents.get(ETYM_INDEX) is None:
            contents[ETYM_INDEX] = title
        else:
            etym = Chapter(ETYM_INDEX,
                           title,
                           etym_match.start(),
                           etym_match.end()+2) # Skip two newlines to reach chapter text offset
            chapters.append(etym)
    
    extracts_re = r'^EXTRACTS .+\.$'
    re_extracts = re.compile(extracts_re, re.MULTILINE)
    extr = None
    EXTR_INDEX = 0
    for extr_match in re_extracts.finditer(MOBY_STR):
        title = extr_match.group()[0:-1] # Take the whole matching string minus the period.
        if contents.get(EXTR_INDEX) is None:
            contents[EXTR_INDEX] = title
        else:
            extr = Chapter(EXTR_INDEX,
                           title,
                           extr_match.start(),
                           extr_match.end()+2) # Skip two newlines to reach chapter text offset
            etym.end_offset = extr.title_offset - 1
            chapters.append(extr)
    
    # The main chapters 1-135 can be chopped up with this regex:
    chapter_re = r'^CHAPTER (?P<ch_num>\d+)\. (?P<ch_title>.+)(?P<title_terminator>[\.\!\?])$'
    re_chapter = re.compile(chapter_re, re.MULTILINE)
    prev_chapter = extr
    for ch_match in re_chapter.finditer(MOBY_STR):
        ch_num = int(ch_match['ch_num'])
        ch_title = ch_match['ch_title']
        terminator = ch_match['title_terminator']
        if terminator == '!' or terminator == '?':
            ch_title += terminator

        # The chapter regex matches twice: once for the contents entry and once for the chapter.
        # So make an entry in contents() the first time a chapter is seen and in chapters() next time.
        if contents.get(ch_num) is None:
            contents[ch_num] = ch_title
        else:
            ch = Chapter(ch_num,
                         ch_title,
                         ch_match.start(),
                         ch_match.end()+2) # Skip two newlines to reach chapter text offset
            if prev_chapter is not None:
                prev_chapter.end_offset = ch.title_offset - 1
            chapters.append(ch)
            prev_chapter = ch
    
    # Fix up the Epilogue and the end offset of chapter 135 just before it.
    re_epilogue = re.compile(r'^Epilogue$', re.MULTILINE)
    ep = None
    for ep_match in re_epilogue.finditer(MOBY_STR):
        if contents.get(136) is None:
            contents[136] = "Epilogue"
        else:
            ep = Chapter(136,
                         "Epilogue",
                         ep_match.start(),
                         ep_match.end()+2) # Skip two newlines to reach chapter text offset
            prev_chapter.end_offset = ep.title_offset - 1
            chapters.append(ep)
            
    # Find the end of the epilogue using the Project Gutenberg end marker
    re_end = re.compile(r'\*\*\* END')
    end_match = re_end.search(MOBY_STR)
    ep.end_offset = end_match.start() - 1
    
    #############################
    # PHASE II - Find paragraphs
    #############################

    # There are two indexes to each paragraph: absolute and relative.
    #
    # The absolute index is simply a 1(one)-based number from the beginning
    # to the end of the book. Paragraphs are delimited solely by one or more
    # blank lines in the text.
    #
    # The relative index is also 1-based, but is relative to each
    # chapter, i.e. this index starts again from 1 (one) within each
    # chapter. So a chapter number must be combined with the relative
    # paragraph index to uniquely identify the paragraph.
    #
    # Chapter titles are not considered paragraphs.
    #
    # In the output, absolute paragraph indices are formatted like "para#123"
    # i.e. "para#<absolute index>". Relative indices look like "para:13:4"
    # i.e. "para:<chapter number>:<relative index>".
    #
    # Some paragraphs are "pre-formatted" text: these are indicated in
    # the Project Gutenberg source file by a two-space indent. This
    # script considers the entire paragram to be pre-formatted if the
    # first line of the paragraph is indented by two spaces.
    #
    # It so happens that the pre-formatted paragraphs are exactly the ones
    # that Melville did not write, i.e. where he's quoting other works.
    #

    # Use the chapters list to drive the cutting into paragraphs.
    # Two or more newlines delimit each paragraph.
    para_end_re = r'[\n]{2,}'
    re_para_end = re.compile(para_end_re, re.MULTILINE)
    para_num = 1 # absolute 1-based index of paragraph in the book
    paragraphs = list()
    for chap in chapters:
        chapter_text = chap.text()
        para_index = 1 # relative index
        para_offset = chap.text_offset
        for para_end_match in re_para_end.finditer(chapter_text):
            match_span_len = para_end_match.end() - para_end_match.start()
            para_end_offset = chap.text_offset + para_end_match.start()
            first_two_chars = MOBY_STR[para_offset:para_offset+2]
            is_pre = (first_two_chars=="  ")
            is_footnote = False
            if is_pre: # all footnotes are pre-formatted in the modified source text
                is_footnote = MOBY_STR[para_offset+2] == '*'
            para = Paragraph(para_num, chap.number, para_index, para_offset, para_end_offset, is_pre, is_footnote)
            paragraphs.append(para)
            para_num += 1
            para_index += 1
            para_offset = chap.text_offset + para_end_match.end()
    
    #############################################
    # PHASE III - Find words, de-flow paragraphs
    #############################################
    
    # In this phase we're going to visit each "lexical" word (i.e. span of non-space
    # characters allowed in a word) and build up a list of words found overall.
    # 
    # Tricky bits and judgement calls:
    #  - The "’" character can appear in contractions in which case we consider it
    #    to be part of the word (e.g. "don’t"), or in forming possesives like "Ahab's"
    #    in which case it (and the trailing "s") are NOT part of the word.
    #  - The "’" character can match by itself the word-regex when used to close embedded
    #    dialogue, so just ignore those.
    #  - Hyphenated words, e.g. "Rose-bud" are considered two words.
    #    + BUT CONSIDER SOME EXCEPTIONS: "Sub-sub", "higgledy-piggledy" **TBD** ???
    #  - Proper nouns and names (e.g. American, Ahab, Rockaway Beach) are a **TBD** challenge!
    #  - We're skipping pre-formatted paragraphs again to focus on paragraphs containing
    #    sentences that Melville wrote, rather than including the quotes & titles etc.
    # 
    # Also along the way here we'll replace line-end characters with spaces to
    # build a "de-flowed" or "joined" paragraph string.
    # 
    # The previous scan to find paragraphs still has a couple of outliers
    # that I'm going to call "wordless" paragraphs (also considered "degenerate").
    # So as we're checking words, for any paragraphs that contain no recognized words
    # we'll mark those as "wordless" (**TBD** or maybe we'll just use Paragraph.word_count == 0 for this?)
    # 
    word_re = r"[a-zA-Z’æéèœ-]+"
    re_word = re.compile(word_re, re.MULTILINE)
    reference_wordlist = WordList.from_file("WORDLIST.TXT")
    additions = WordList.from_file("WORDLIST-additions.TXT")
    hyphenated = WordList.from_file("MOBY-HYPHENATED.TXT")
    reference_wordlist.add_wordlist(additions)
    reference_wordlist.add_wordlist(hyphenated)
    names = WordList.from_file("MOBY-NAMES.TXT")
    moby_words = WordList()
    moby_nonwords = WordList()
    for para in paragraphs:
        if not para.is_pre:
            para_text = para.text()
            # Debug output
            #print()
            #print(para)
            #print()
            for word_match in re_word.finditer(para_text):
                word_str = word_match.group().upper()
                # Continuation cases, just skip these
                if word_str == "’":
                    continue
                # Chop trailing "’s"
                if word_str.endswith("’S"):
                    word_str = word_str[:-2]
                # Chop trailing "’" from "*s’" words like "days'"
                if word_str.endswith("S’"):
                    word_str = word_str[:-1]
                word = Word(word_str)
                if reference_wordlist.contains_word(word):
                    moby_words.add_word(word)
                elif not names.contains_word(word):
                    moby_nonwords.add_word(word)
             
    moby_words.sort()
    moby_nonwords.sort()

    print()
    print("============= MOBY-WORDS")
    for w in moby_words.word_list:
        print(w)
    
    print()
    print("============= NON-WORDS")
    for w in moby_nonwords.word_list:
        print(w)
    
    print()
    print("============= WORDLEABLE")
    wordleable = WordList.from_file("ALL-WORDLEABLE")
    prev_letter = ''
    for w in moby_words.word_list:
        if wordleable.contains_word(w):
            print(w)
        
    #print("N chapters:", len(chapters))
    #print("N paragraphs:", len(paragraphs))
    
    print("N Moby words:", len(moby_words))
    
if __name__ == "__main__":
    split_moby_dick("pg2701-modified.txt")
    
